In the following section, we restrict our attention to the use of Lagrangian analysis as an in situ data reduction strategy and the relevant research on distributed-memory particle advection.

\textbf{Lagrangian Analysis.}
%
In the Lagrangian specification of a time-varying vector field, information is stored using integral curves, where each curve encodes the trajectory of a single massless particle.
%
Each integral curve provides insight regarding flow behavior in the vicinity of the particle's trajectory~\cite{bujack2015lagrangian}.
%
Collectively, a large number of integral curves spanning the spatial domain can be defined in terms of a flow map, i.e., a Lagrangian representation of the flow field.
%
The flow map $F_{t_0}^{t}(x_0):\mathbb R^d \times \mathbb R \times \mathbb R  \to \mathbb R^d$ describes to where a particle starting at position $x_0\in \mathbb R^d$ and time $t_0\in \mathbb R$ moves in the time interval $[t_0,t]\subset \mathbb R$~\cite{garth2007efficient}.
%

Agranovsky et al.~\cite{agranovsky2014improved} proposed a two phase approach: (1) use in situ processing to compute reduced Lagrangian flow maps, and (2) interpolate the flow maps for time-varying vector field exploration.
%
The study demonstrated significantly improved accuracy-storage propositions for exploration under sparse temporal settings compared to the traditional Eulerian approach.
%
The Eulerian approach is susceptible to error due to high numerical approximation in settings of temporal sparsity~\cite{costa2004lagrangian,Qin2014,agranovsky2014improved,sane2018revisiting,rockwood2019practical}. 
%
In comparison, the Lagrangian approach benefits from access to the complete spatiotemporal resolution to compute flow maps.
%
Multiple works have advanced this research area by considering in situ sampling or extraction strategies~\cite{sane2019interpolation, rapp2019void}, post hoc reconstruction and theoretical/empirical error analysis using the flow map as input~\cite{hlawatsch2011hierarchical, agranovsky2015multi, bujack2015lagrangian, chandler2015interpolation, chandler2016analysis, hummel2016error, sane2018revisiting, sane2019interpolation, rapp2019void, jakob2020fluid}, and the use of reduced data sets for analysis of ocean modeling applications~\cite{envirvis.20171099}.

In this paper, we focus on the first phase, i.e., in situ computation of a Lagrangian flow map.
%
Agranovsky et al.~\cite{agranovsky2014improved} considered a strategy prioritizing domain coverage.
%
Particles were seeded along a uniform grid, interpolated for a fixed number of cycles, i.e., \textit{storage interval}, and reset to repeat the process until the end of the simulation.
%
Their study used CPUs on as many as 128 CNs.
%
Two other works have proposed relevant sampling strategies. 
%
First, Sane et al.~\cite{sane2019interpolation} proposed tracing longer trajectories, while storing intermediate particle locations at fixed storage intervals. 
%
In this approach, as particles diverged and clustered, a reconstruction error-guided sampling strategy added or removed particles.
%
Second, Rapp et al.~\cite{rapp2019void} applied a statistical sampling strategy based on the blue noise property to the extraction of particle trajectories. 
%
Although these strategies can yield an improved reconstruction compared to uniform or random sampling, they are limited to a single CN, and they require additional research to keep execution time and/or memory requirements acceptable in a distributed-memory setting. 
%
Execution time and memory are limited resources when operating in situ, so the task of efficiently computing a Lagrangian flow map in distributed-memory remains challenging.

\textbf{Distributed-Memory Particle Advection.}
%
Distributed-memory particle advection algorithms have historically been proposed for post hoc analysis.
%
We refer readers to comprehensive surveys~\cite{PeterkaRNLSKH11,zhang2018survey} on this topic for steady and unsteady vector fields in multinode settings.
%
However, the existing post hoc solutions are not directly applicable due to the different constraints and requirements of computing a Lagrangian flow map in situ.
%
We identify and list these differences in Table~\ref{table:differences}.

The most significant challenge associated with distributed-memory particle advection is scalability.
%
Poor scalability is due to the frequent and large amount of communication required between processors as particles continue trajectory integration across rank domain boundaries.
%
Most studies in this area have required particle exchange, but a few have used preprocessing or runtime operations to address scalability by limiting communication.
%
Notably, Chen et al.~\cite{ChenXLS12, ChenS13} and Liao et al.~\cite{Liao2019ScalablePF} modify the data layout as a preprocessing step to propose parallelize-over-data techniques.
%
Using parallelize-over-particles strategies, Guo et al.~\cite{GuoHSZHY14} and Zhang et al.~\cite{ZhangGY16} moved and duplicated data between processors or used on-demand data loading.
%
Lastly, as an advection acceleration strategy, Bleile et al.~\cite{bleile2017accelerating} computed block-specific flow maps for a single time-slice as a communication-free preprocess and used the mapping to transport particles across entire blocks in a single step. 
%
Considering in situ constraints, and the time-varying nature of the data, existing strategies are either not applicable or viable. 
%

In this paper, we consider a communication-free model for extracting local Lagrangian flow maps. 
%
We compare this approach with the traditional computation of a Lagrangian flow map, which does incur communication costs.
%
Our comparisons are at scale and evaluate the respective performance benefits and reconstruction accuracy of the approach.
%
Based on our understanding of existing research in this area, in situ constraints, and practical temporal storage intervals, we believe the communication-free model is viable for a sampling strategy, and most importantly, intrinsically enables scalability to a large number of processors.

